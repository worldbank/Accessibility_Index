{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "light-prescription",
   "metadata": {},
   "source": [
    "# Walking friction surface creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-excess",
   "metadata": {},
   "source": [
    "Clean up various rasters and combining them into a walking friction surface. This forms half of the multi-modal friction surface and can also be used as a standalone analysis tool (for walking-only analysis). This will later be merged with an on-road friction surface for a final product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import common_rasterio_ops as rast_ops # custom functions\n",
    "\n",
    "import numpy as np\n",
    "from numpy import pi, log, tan, empty, float32, arctan, rad2deg, gradient\n",
    "from numpy import arctan2, reshape, where\n",
    "from scipy.ndimage import gaussian_gradient_magnitude\n",
    "\n",
    "import rasterio\n",
    "from rasterio import features, transform\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.io import MemoryFile\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import shape, box, Polygon\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc9a08-8acb-4dc9-a938-0d1e4e51b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'D:\\\\github_test\\\\'\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read project input parameters that will eventually be passed from the UI\n",
    "data_file = data_root + 'project_data.json'\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read project variables that will come from UI so that we have our parameters and file locations\n",
    "with open(data_file, 'rb') as f:\n",
    "    data_loaded = json.load(f)\n",
    "f.close()\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read information from the project setup file that's relevant to this section of code\n",
    "#imports\n",
    "local_dem_folder = data_loaded['local_dem_folder']\n",
    "local_lc_folder = data_loaded['local_lc_folder']\n",
    "local_lc_folder_non_seasonal = data_loaded['local_lc_folder_non_seasonal']\n",
    "local_roads_folder = data_loaded['local_roads_folder']\n",
    "local_water_folder = data_loaded['local_waterways_folder']\n",
    "local_boundaries_folder = data_loaded['local_boundaries_folder']\n",
    "force_rivers = data_loaded['force_rivers']\n",
    "fric_dir = data_loaded['fric_dir']\n",
    "dest_crs = data_loaded['dest_crs']\n",
    "dest_crs_id = data_loaded['dest_crs_id']\n",
    "buffer_m = data_loaded['buffer_m']\n",
    "level = data_loaded['level']\n",
    "seasonal_lc = data_loaded['seasonal_lc']\n",
    "if level != 'custom':\n",
    "    shapefile_adm_field = data_loaded['shapefile_adm_field']\n",
    "    adm_name = data_loaded['adm_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7381003-ab67-4c0b-92f8-b2f0b9383db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if seasonal_lc == 1:\n",
    "    lc_folder_final = local_lc_folder\n",
    "\n",
    "else: \n",
    "    lc_folder_final = local_lc_folder_non_seasonal\n",
    "\n",
    "    lc_file_generic = sorted([os.path.join(lc_folder_final,file) \\\n",
    "                for file \\\n",
    "                in os.listdir(lc_folder_final) \\\n",
    "                if file.endswith(\".tif\")])\n",
    "\n",
    "    lc_file_generic = lc_file_generic[0]\n",
    "    \n",
    "seasons = sorted([os.path.join(local_lc_folder,file) \\\n",
    "            for file \\\n",
    "            in os.listdir(local_lc_folder) \\\n",
    "            if file.endswith(\".txt\")])\n",
    "\n",
    "for strnum in range(0, len(seasons)):\n",
    "    seasons[strnum] = str.replace(seasons[strnum], local_lc_folder,\"\")\n",
    "    seasons[strnum] = str.replace(seasons[strnum], \".txt\",\"\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817166c-43f3-4ed4-8f63-5bb554e5921d",
   "metadata": {},
   "source": [
    "Load Shapefile of area of interest to clip the final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28e81c-2d7b-46f8-a42b-1d6d8aef49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_pth = local_boundaries_folder + level + '\\\\'\n",
    "\n",
    "aoi_file = sorted([os.path.join(aoi_pth,file) \\\n",
    "            for file \\\n",
    "            in os.listdir(aoi_pth) \\\n",
    "            if file.endswith(\".shp\")])\n",
    "\n",
    "aoi_file = aoi_file[0]\n",
    "\n",
    "aoi = gpd.read_file(aoi_file)\n",
    "\n",
    "aoi = aoi[aoi[shapefile_adm_field] == adm_name]\n",
    "aoi = aoi.to_crs(dest_crs)\n",
    "\n",
    "# Buffer the polygon so we take in nearby markets and roads that may be used\n",
    "aoi.geometry = aoi.buffer(buffer_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-stage",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-thirty",
   "metadata": {},
   "source": [
    "Load in and process various input rasters for off-road travel. Note that the decision to use the landcover as the reference layer (in terms of projection, cell size, etc.) is arbitrary and the DEM could easily be used for such instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-adult",
   "metadata": {},
   "source": [
    "## Reclassify landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee94076-2c38-47b9-afde-423a2569066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a \"lookup array\" where the index is the original value and the value\n",
    "# is the reclassified value.  Setting all of the reclassified values is cheap \n",
    "# because the memory is only allocated once for the lookup array.\n",
    "# Replacement values are the divisors of walking speeds specific to the landcover classes specified in the file \"class_speed_modifiers.csv\" in your inputs landcover folder\n",
    "# THESE ARE EXAMPLE VALUES SET FOR GOOGLE DYNAMIC WORLD DATASETS AND MUST BE REPLACED FOR YOUR CONTEXT \n",
    "# Always verify that the landcover class values in your rasters correspond correctly to the raster_value in the .csv file\n",
    "# There are different land cover class numbering schemes between different datasets, so always check\n",
    "# refer to \"Spatial Analysis by Cost Functions\" by Irmela Herzog (2020) for guidance on modifier values\n",
    "\n",
    "lookup = np.arange(256, dtype=np.float32)\n",
    "lookup[:] = 1.5 #default values for classes not specified\n",
    "\n",
    "csv_file_loc = local_lc_folder + 'class_speed_modifiers.csv'\n",
    "\n",
    "df_comma = pd.read_csv(csv_file_loc, nrows=1,sep=\",\")\n",
    "df_semi = pd.read_csv(csv_file_loc, nrows=1, sep=\";\")\n",
    "\n",
    "if df_comma.shape[1]>df_semi.shape[1]:\n",
    "    modifiers =  pd.read_csv(csv_file_loc, sep=',')\n",
    "else:\n",
    "    modifiers =  pd.read_csv(csv_file_loc, sep=';')\n",
    "\n",
    "for class_num in range(0,len(modifiers)):\n",
    "    lookup[int(modifiers.loc[class_num,'raster_value'])] = modifiers.loc[class_num,'modifier']\n",
    "    if force_rivers == 1:\n",
    "        if modifiers.loc[class_num,'water'] == 'yes':\n",
    "            water_divider = modifiers.loc[class_num,'modifier'] # for when rivers are forced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9610b7d-c95a-4113-afc6-b7a0f03e9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rivers and bridges as obstacles\n",
    "\n",
    "if force_rivers == 1:\n",
    "\n",
    "    rivers_file = sorted([os.path.join(local_water_folder,file) \\\n",
    "            for file \\\n",
    "            in os.listdir(local_water_folder) \\\n",
    "            if file.endswith(\".shp\")])\n",
    "\n",
    "    rivers_file = rivers_file[0]\n",
    "\n",
    "    # local file import\n",
    "    rivs = gpd.read_file(rivers_file,driver=\"ESRI Shapefile\")\n",
    "\n",
    "    # minor cleanup\n",
    "    rivs = rivs.reset_index()\n",
    "    rivs_slim = rivs[['geometry']]\n",
    "    rivs_slim['exist'] = 1\n",
    "    rivs_slim = rivs_slim.to_crs(dest_crs)\n",
    "\n",
    "    # create a generator containing geometry, value pairs for rivers\n",
    "\n",
    "    riv_shapes = ((geom,exist) for geom, exist in zip(rivs_slim.geometry,rivs_slim['exist']))\n",
    "\n",
    "    # This will give the raster the size and dimensions of the landcover raster -- areas not covered by rivers will be 0.\n",
    "        \n",
    "    riv_rast = features.rasterize(riv_shapes,\\\n",
    "                      out_shape = (lc_profile['height'],\\\n",
    "                                   lc_profile['width']),\\\n",
    "                      transform=lc_profile['transform'],\n",
    "                      all_touched=True,\n",
    "                      fill=0,\n",
    "                      dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645bb63-e90c-4740-957f-b3d2f761dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read a lc file to get the right export profile\n",
    "if seasonal_lc ==0:\n",
    "    profile_load_location = lc_file_generic\n",
    "else:\n",
    "    profile_load_location = lc_folder_final+seasons[0]+'.tif'\n",
    "    \n",
    "with rasterio.open(profile_load_location) as lc_src:\n",
    "        # Read as numpy array\n",
    "        lc_profile = lc_src.profile\n",
    "\n",
    "## Roads to walking surface mask raster\n",
    "#We assume that people walking on roads and paths are not affected by landcover. To model this we turn roads into a raster with value = 1 (for 1 * speed). Then we merge it with the landcover raster for a final walking speed modifier raster\n",
    "\n",
    "roads_file = local_roads_folder + 'final_roads.gpkg'\n",
    "\n",
    "rds = gpd.read_file(os.path.join(roads_file),driver=\"gpkg\")\n",
    "\n",
    "# assign 1 value to represent existence of road\n",
    "rds['exist'] = 1\n",
    "\n",
    "# generator of vector shapes and values (boolean)\n",
    "rds_shapes = ((geom,exist_val) for geom, exist_val in zip(rds.geometry,rds['exist']))\n",
    "\n",
    "# This will give the raster the size and dimensions of the landcover raster -- areas not covered by roads will be 0.\n",
    "\n",
    "rd_mask_rast = features.rasterize(rds_shapes,\\\n",
    "                  out_shape = (lc_profile['height'],\\\n",
    "                               lc_profile['width']),\\\n",
    "                  transform=lc_profile['transform'],\n",
    "                  all_touched=True,\n",
    "                  fill=0,\n",
    "                  dtype = np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98225b7e-c1a2-4a3b-b3c3-608c78c596ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Base walking speeds from DEM\n",
    "\n",
    "#### DEM to slope\n",
    "\n",
    "#First import the DEM and transform it to the same CRS, cell resolution, and dimensions as the landcover layer. This enables raster math between the layers and any other arrays derived from them.\n",
    "\n",
    "dem_file = sorted([os.path.join(local_dem_folder,file) \\\n",
    "            for file \\\n",
    "            in os.listdir(local_dem_folder) \\\n",
    "            if file.endswith(\".tif\")])\n",
    "\n",
    "dem_file = dem_file[0]\n",
    "\n",
    "with rasterio.open(dem_file) as dem_src:\n",
    "    # Read as numpy array\n",
    "    dem_array = dem_src.read(1)\n",
    "    dem_transform = dem_src.transform\n",
    "    dem_profile = dem_src.profile\n",
    "\n",
    "#dem_array_reproj.profile\n",
    "dem_array = np.round(dem_array,0).astype(np.float32)\n",
    "\n",
    "# use get_slope function from common_rasterio_ops\n",
    "slope = rast_ops.get_slope(dem_array,mode='fraction')\n",
    "\n",
    "# remove artefacts that will produce slopes > 100%\n",
    "slope = np.where(slope>1,1,slope)\n",
    "\n",
    "#Calculate walking speeds over the slope using Irmischer and Clarke's 2018 walking speed formula.\n",
    "# Irmischer and Clarke have a generic off-road speed formula but we don't use this given that we adjust by specific landcover type.  Rather, we modify their on-road speed.\n",
    "# We include the I+C off-road formula below for reference\n",
    "\n",
    "# walkspeed_offroad = (0.11 + (0.67 * np.exp(-np.square((slope*100) + 2) / 3600))) * 3.6 # I-C off-road\n",
    "walkspeed_onroad = (0.11 + np.exp(-np.square((slope*100) + 5) / 3600)) * 3.6\n",
    "\n",
    "walkspeed_base = walkspeed_onroad\n",
    "# walkspeed_base = np.where(rd_mask_rast == 1,walkspeed_onroad,walkspeed_offroad) # included for reference purposes, in situations where you don't want to adjust by landcover\n",
    "\n",
    "#save memory\n",
    "del walkspeed_onroad\n",
    "\n",
    "#### Vertical distances\n",
    "#Calculate the additional vertical distance covered when crossing a cell (the rise, in addition to the run represented by the cell's resolution).\n",
    "\n",
    "vert_dist_simple = 1 / np.cos(slope)\n",
    "\n",
    "#Calculate the additional distance associated with zig-zagging paths - the zig goes sideways halfway up the cell, the zag sideways up the other half. We do not consider circumstances with more than 2 zig zags per cell -- possibly problematic if using large cells (1km+)\n",
    "# The switchback cutoff value is somewhat arbitrary and perhaps even varies by culture / context. \n",
    "# We use one of the higher values found in the literature as residents of the Himalayas might be expected to have a high tolerance for walking up steep hills\n",
    "\n",
    "switchback_cutoff = 0.20 #0.3 for himalayas\n",
    "vert_dist_switchback = np.tan(slope) / np.sin(switchback_cutoff)\n",
    "\n",
    "#Combine the two arrays into one walking cost array, forcing walkers to use zig-zagging switchbacks while crossing terrain above a cutoff slope of `30%` (0.30). \n",
    "\n",
    "vert_dist_switchback = np.where(slope <= switchback_cutoff,vert_dist_simple,vert_dist_switchback)\n",
    "\n",
    "#save memory\n",
    "del slope\n",
    "\n",
    "# make float32 to reduce file sizes on export\n",
    "# vert_dist_simple = vert_dist_simple.astype(np.float32)\n",
    "del vert_dist_simple\n",
    "vert_dist_switchback = vert_dist_switchback.astype(np.float32)\n",
    "\n",
    "# Create a profile for clipping the layers\n",
    "\n",
    "export_profile = lc_profile.copy()\n",
    "export_profile.update({\"dtype\":'float32',\\\n",
    "                       \"COMPRESS\":'ZSTD',\n",
    "                       \"NUM_THREADS\":'ALL_CPUS',\n",
    "                       \"nodata\":-99999})\n",
    "\n",
    "vert_dist_switchback_mask, vert_dist_switchback_mask_tform = rast_ops.clip_in_memory(vert_dist_switchback,export_profile, aoi.geometry)\n",
    "\n",
    "export_profile_switch = export_profile.copy()\n",
    "export_profile_switch['transform'] = vert_dist_switchback_mask_tform\n",
    "export_profile_switch['width'] = vert_dist_switchback_mask.shape[1]\n",
    "export_profile_switch['height'] = vert_dist_switchback_mask.shape[0]\n",
    "\n",
    "with rasterio.open(\n",
    "        os.path.join(local_dem_folder,'vert_dist_switchback.tif'), 'w',**export_profile_switch) as dst:\n",
    "    dst.write(vert_dist_switchback_mask, indexes=1)\n",
    "    dst.build_overviews = ([2,4,8,10,14,16],Resampling.nearest)\n",
    "\n",
    "del vert_dist_switchback_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022270b9-29c1-40dc-ab13-7e87b0fecc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if seasonal_lc == 0:\n",
    "\n",
    "    with rasterio.open(lc_file_generic) as lc_src:\n",
    "            # Read as numpy array\n",
    "            lc_array = lc_src.read()\n",
    "            lc_profile = lc_src.profile\n",
    "            lc_transform = lc_src.transform\n",
    "\n",
    "    lc_array = lc_array.astype(np.int8)\n",
    "    \n",
    "    # Reclassify in a single operation using broadcasting\n",
    "    lc_array = lookup[lc_array].astype(np.float16)\n",
    "\n",
    "for season_num in range(0, len(seasons)):\n",
    "    \n",
    "    current_season = seasons[season_num]\n",
    "\n",
    "    if seasonal_lc == 1:\n",
    "        with rasterio.open(os.path.join(lc_folder_final,current_season+'.tif')) as lc_src:\n",
    "            # Read as numpy array\n",
    "            lc_array = lc_src.read()\n",
    "            lc_profile = lc_src.profile\n",
    "            lc_transform = lc_src.transform\n",
    "\n",
    "        lc_array = lc_array.astype(np.int8)\n",
    "    \n",
    "        # Reclassify in a single operation using broadcasting\n",
    "        lc_array = lookup[lc_array].astype(np.float16)\n",
    "\n",
    "    #First combine the rivers with the landcover raster, inserting a `600000` divider where rivers exist, so crossing rivers without a bridge has a huge cost. Then combine with the road mask, inserting a `1` multiplier where roads are. The order is important, so roads overwrite rivers (implicitly via bridges, which are not reliably recorded in many roads datasets)\n",
    "    #</br></br>Note that if landcover *multipliers* instead of *dividers* are used, you need to invert this and use a very small decimal value for the rivers.\n",
    "\n",
    "    if force_rivers == 1:\n",
    "        # force dividers on water from shapefiles, in addition to satellite imagery\n",
    "        walkspeed_mod_rast = np.where(riv_rast == 1, water_divider, lc_array)\n",
    "        # del riv_rast\n",
    "    else:\n",
    "        walkspeed_mod_rast = lc_array \n",
    "\n",
    "    walkspeed_mod_rast = walkspeed_mod_rast[0, :, : ]\n",
    "    \n",
    "    # del lc_array\n",
    "    walkspeed_mod_rast = walkspeed_mod_rast.astype(np.float16)\n",
    "    walkspeed_mod_rast = np.round(walkspeed_mod_rast,1).astype(np.float16)\n",
    "\n",
    "    # treat roads as bridging rivers by default\n",
    "    walkspeed_mod_rast = np.where(rd_mask_rast == 1, 1, walkspeed_mod_rast).astype(np.float16)\n",
    "        \n",
    "    ## Merge rasters into final walking friction surface\n",
    "\n",
    "    # Combine the various arrays into a final walking friction surface in 6 stages:\n",
    "    # 1. Multiply the base walking speed computed from the DEM Slope by the speed modifier\n",
    "    # 2. Create a monsoon walking speed as 0.75 of the base walking speed and the winter walking speed similarly, using a multiplier determined by elevation\n",
    "    # 3. Adjust the speeds for altitude\n",
    "    # 4. Transform these speeds into friction values\n",
    "    # 5. Multiply the friction values by the vert/horizontal multiplication factor (e.g. 1.5)\n",
    "    # 6. Convert extraneous values to -99999 nodata values\n",
    "    \n",
    "    walkspeed_step1 = np.divide(walkspeed_base,walkspeed_mod_rast)\n",
    "    txt_file = local_lc_folder + current_season + '.txt'\n",
    "\n",
    "    with open(txt_file, 'r') as file:\n",
    "                # Read the first line\n",
    "                seasonal_walk_multiplier = float(file.readline().strip())\n",
    "    \n",
    "    walkspeed_step1 = np.multiply(walkspeed_step1,seasonal_walk_multiplier)\n",
    "\n",
    "    walkspeed_step1 = walkspeed_step1.astype(np.float32)\n",
    "\n",
    "    # Adjust walkspeeds by altitude\n",
    "    # We adjust altitude in two steps based on a literature review into how lower oxygen content at altitude affects walking speeds. Note this is not the best documented subject, at least in terms we can computer into a friction surface.\n",
    "    # This formula could probably be streamlined so that this step is condensed into one move\n",
    "    # The Global Friction Surface has just one formula but I found its high altitude (>5000) modifiers to be a little low compared to the available literature on athletic performance at altitude. Not a big deal except if you're working in the Himalayas\n",
    "\n",
    "    alt_adjust_under3k = np.where(dem_array <= 2350, walkspeed_step1, ((walkspeed_step1) / (1 + ((dem_array - 2350)/5000))) )\n",
    "    walkspeed_step2 = np.where(dem_array <= 3000, alt_adjust_under3k, ((walkspeed_step1) / (0.323 * np.exp((.00042*dem_array)))) )\n",
    "\n",
    "    # save memory \n",
    "    del alt_adjust_under3k, walkspeed_step1\n",
    "\n",
    "    # Refactor walking speeds to friction values in units of cell size / hour (e.g. 30m / hour)\n",
    "    # To prepare by minute instead just multiply by 60\n",
    "    friction_walk_step1 = (1 / walkspeed_step2) / (1000 / lc_transform.a)\n",
    "\n",
    "    # save memory\n",
    "    del walkspeed_step2\n",
    "\n",
    "    # Now multiply the friction surface by the merged vertical/horizontal distance to calculate the final friction surface\n",
    "    friction_walk_final = np.multiply(friction_walk_step1,vert_dist_switchback)\n",
    "\n",
    "    # Weed out Inf values and super high river values\n",
    "    # We use 1 as an arbitrary cutoff on the assumption that it will never actually take 1 hour to cross a grid cell, so values above that are bogus and filterable\n",
    "\n",
    "    friction_walk_final = np.where(friction_walk_final > 1, 1, friction_walk_final)\n",
    "    friction_walk_final = np.round(friction_walk_final,8).astype(np.float32)       \n",
    "    friction_walk_final_mask, friction_walk_mask_tform = rast_ops.clip_in_memory(friction_walk_final,export_profile, aoi.geometry)\n",
    "    \n",
    "    export_profile2 = export_profile.copy()\n",
    "    export_profile2['transform'] = friction_walk_mask_tform\n",
    "    export_profile2['width'] = friction_walk_final_mask.shape[1]\n",
    "    export_profile2['height'] = friction_walk_final_mask.shape[0]\n",
    "    \n",
    "    with rasterio.open(\n",
    "            os.path.join(fric_dir,current_season+'_walk.tif'), 'w',**export_profile2) as dst:\n",
    "        dst.write(friction_walk_final_mask, indexes=1)\n",
    "        dst.build_overviews = ([2,4,8,10,14,16],Resampling.nearest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (git)",
   "language": "python",
   "name": "git"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
