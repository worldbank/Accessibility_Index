{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8196a875-0330-4d4c-8bc1-c2b4df184bfa",
   "metadata": {},
   "source": [
    "# Export population raster points with their administrative population weights, and administrative units (using spatial joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7da9c-e1c1-4e1f-9461-3bce9befb195",
   "metadata": {},
   "source": [
    "This notebook exports each season-mode-service raster's pixels to their corresponding populated points, and calcualtes their pop-weighted access times for aggregation in future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e304e630-6809-47d7-9132-cf5c31d77612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "import dask\n",
    "import coiled\n",
    "from dask.distributed import Client, LocalCluster, Lock\n",
    "from dask.utils import SerializableLock\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import spatialpandas as sp\n",
    "import dask_geopandas as dg\n",
    "\n",
    "import rioxarray as rx\n",
    "import xarray as xr\n",
    "\n",
    "import re\n",
    "\n",
    "from dask_control import *\n",
    "from raster_vals_to_pts import *\n",
    "\n",
    "import numpy as np\n",
    "dask.config.set({\"temporary-directory\": \"C:/Users/andri\"})\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02d36f-8289-450d-99ef-63c696308d62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_root = 'D:\\\\github_test\\\\'\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read project input parameters \n",
    "data_file = data_root + 'project_data.json'\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read project variables so that we have our parameters and file locations\n",
    "with open(data_file, 'rb') as f:\n",
    "    data_loaded = json.load(f)\n",
    "f.close()\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read information from the project setup file that's relevant to this section of code\n",
    "#imports\n",
    "local_population_folder = data_loaded['local_population_folder']\n",
    "local_lc_folder = data_loaded['local_lc_folder']\n",
    "access_dir = data_loaded['access_dir']\n",
    "dest_crs = data_loaded['dest_crs']\n",
    "dest_crs_id = data_loaded['dest_crs_id']\n",
    "\n",
    "local_boundaries_folder = data_loaded['local_boundaries_folder']\n",
    "level = data_loaded['level']\n",
    "max_level = data_loaded['max_level']\n",
    "if level != 'custom':\n",
    "    shapefile_adm_field = data_loaded['shapefile_adm_field']\n",
    "    adm_name = data_loaded['adm_name']\n",
    "\n",
    "seasons = sorted([os.path.join(local_lc_folder,file) \\\n",
    "            for file \\\n",
    "            in os.listdir(local_lc_folder) \\\n",
    "            if file.endswith(\".tif\")])\n",
    "\n",
    "for strnum in range(0, len(seasons)):\n",
    "    seasons[strnum] = str.replace(seasons[strnum], local_lc_folder,\"\")\n",
    "    seasons[strnum] = str.replace(seasons[strnum], \".tif\",\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2c609-a0d4-4f50-86d3-e810dd0c7372",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_list =['walk','multi']\n",
    "ssn_mode_list = []\n",
    "for ssn in seasons:\n",
    "    for mode_num in range(0,len(mode_list)):\n",
    "        ssn_mode_list.append(ssn + \"_\" + mode_list[mode_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe3f07-cf30-47e7-b8c8-fff2d196ca01",
   "metadata": {},
   "source": [
    "Instantiate Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e219b0-8ab5-473c-bed9-229d65584ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=get_dask_client(cluster_type='local',n_workers=4,processes=True,threads_per_worker=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717a8981-c164-4285-a9fa-0e256e2d2d11",
   "metadata": {},
   "source": [
    "Read in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1765ba-b418-4b65-8740-6150fc574853",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_population_folder+'population_tabular_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553292c5-c2ea-4791-bc5d-003929aa3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Points\n",
    "if max_level == 'adm2':\n",
    "    col_range = [0,3,4,6,8]\n",
    "    col_names = [\"POP\",\"x\",\"y\",\"ADM2_EN\",\"Adm2_Code\"]\n",
    "    col_types = {\"POP\": float,\"x\": float,\"y\": float,\"ADM2_EN\": str,\"Adm2_Code\": str}\n",
    "else:\n",
    "    col_range = [0,3,4,6,7,9,10]\n",
    "    col_names = [\"POP\",\"x\",\"y\",\"ADM2_EN\",\"ADM3_EN\",\"Adm2_Code\",\"Adm3_Code\"]\n",
    "    col_types = {\"POP\": float,\"x\": float,\"y\": float,\"ADM2_EN\": str,\"Adm2_Code\": str,\"ADM3_EN\": str,\"Adm3_Code\": str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d622099-184d-4351-8f23-7a69ded8a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = dd.read_csv(local_population_folder+'population_tabular_final.csv',\n",
    "                     skip_blank_lines=True,\n",
    "                     usecols = col_range,\n",
    "                     header=None,\n",
    "                     names= col_names,\n",
    "                     dtype = col_types,\n",
    "                     na_values = ['', ' ', 'N/A', '#N/A', 'NA', '#NA'],\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c35e3-eac9-4a14-99be-10bd3d5e8ed6",
   "metadata": {},
   "source": [
    "Process rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662e97b-1ce6-4d16-aed9-a79b6f866380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forst we prepare the 'base' dataframe with all points' coordinates and corresponding adm data\n",
    "points_xr = xr.Dataset.from_dataframe(points[[\"x\", \"y\"]])\n",
    "if max_level == 'adm2':\n",
    "    df_pixels_source = points[['POP','x','y','ADM2_EN','Adm2_Code']].copy()\n",
    "else:\n",
    "    df_pixels_source = points[['POP','x','y','ADM3_EN','Adm3_Code','ADM2_EN','Adm2_Code']].copy()\n",
    "\n",
    "df_pixels_source = df_pixels_source.repartition(npartitions=1)\n",
    "df_pixels_source = df_pixels_source.reset_index(drop=True)\n",
    "\n",
    "# Get Pops per Adm2 unit\n",
    "adm2_pop = df_pixels_source.groupby('Adm2_Code')['POP'].sum().to_frame(\"adm2_pop\")\n",
    "\n",
    "if max_level == 'adm3':\n",
    "    # Get Pops per Adm3 unit\n",
    "    adm3_pop = df_pixels_source.groupby('Adm3_Code')['POP'].sum().to_frame(\"adm3_pop\")\n",
    "\n",
    "df_pixels_source = dd.merge(df_pixels_source, adm2_pop, how = 'left', left_on=\"Adm2_Code\", right_index=True)\n",
    "if max_level == 'adm3':\n",
    "    df_pixels_source = dd.merge(df_pixels_source, adm3_pop, how = 'left', left_on=\"Adm3_Code\", right_index=True)\n",
    "\n",
    "df_pixels_source = df_pixels_source.persist()\n",
    "\n",
    "# Calculate the population weight of each pixel within its enclosing admin area -- e.g. 10 pixel population for a 100 population admin - 0.1 weight\n",
    "df_pixels_source['wt_adm_2'] = (df_pixels_source['POP'] / df_pixels_source['adm2_pop'])\n",
    "if max_level == 'adm3':\n",
    "    df_pixels_source['wt_adm_3'] = (df_pixels_source['POP'] / df_pixels_source['adm3_pop'])\n",
    "    \n",
    "del points, adm2_pop\n",
    "if max_level == 'adm3':\n",
    "    del adm3_pop\n",
    "\n",
    "df_pixels_source = df_pixels_source.drop(['adm2_pop'], axis = 1)\n",
    "if max_level == 'adm3':\n",
    "    df_pixels_source = df_pixels_source.drop(['adm3_pop'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a400ba-884c-407e-a15d-dd662715931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all the season-mode combinations and export pixel values \n",
    "# season-mode pixel file(s) will be created, containing each pixel's \n",
    "# service access time and its pop-weighted service access time, for all services\n",
    "\n",
    "for ssn_mode_num in range(0, len(ssn_mode_list)):\n",
    "    ssn_mode = ssn_mode_list[ssn_mode_num]\n",
    "    print(ssn_mode)\n",
    "    \n",
    "    rasters = {}\n",
    "    rlimit = len(os.listdir(access_dir))\n",
    "    r_ct = 0\n",
    "\n",
    "    # get a list of the access time rasters for specific season-mode\n",
    "    for file in os.listdir(access_dir):\n",
    "        if file.endswith(\".tif\"):\n",
    "            if file.startswith(f'{ssn_mode}_'):\n",
    "                acc_rast = re.search(f'(.*?).tif',os.path.basename(file)).group(1)\n",
    "                rasters[acc_rast] = f\"{access_dir}{file}\"\n",
    "                r_ct = r_ct + 1\n",
    "                if r_ct >= rlimit:\n",
    "                    break\n",
    "   \n",
    "    loaded_rasters = {}\n",
    "    for key in rasters:\n",
    "        print(f\"Persist raster: {key} at {rasters[key]}\")\n",
    "        raster = xr.open_rasterio(f\"{rasters[key]}\", \n",
    "                                       chunks = (\"auto\", \"auto\", \"auto\"),\n",
    "                                       parse_coordinates=True)        \n",
    "        loaded_rasters[key] = raster\n",
    "  \n",
    "    rasters_ds = (\n",
    "        xr.Dataset(loaded_rasters)\n",
    "        .sel(band=1)\n",
    "        .map(lambda arr: arr.where(arr != arr.nodatavals[0]))\n",
    "    )\n",
    "\n",
    "    # now start preparing the dataframe for this specific season-mode\n",
    "    df_pixels = df_pixels_source\n",
    "\n",
    "    # for each access time raster, add access time raster points values to columns in the dataframe\n",
    "    first = 1\n",
    "    for rkey in rasters:\n",
    "        print(rkey)\n",
    "        hrs_col = f\"{rkey}\"\n",
    "        pixel_values_temp = rasters_ds[hrs_col].sel(x=points_xr.x, y=points_xr.y, method=\"nearest\")\n",
    "        pixel_values_temp = pixel_values_temp.reset_coords(drop=True).to_dataframe(name=hrs_col).reset_index()\n",
    "        pixel_values_temp = dd.from_pandas(pixel_values_temp, npartitions=1)\n",
    "        \n",
    "        if first == 1:\n",
    "            pixel_values = pixel_values_temp.copy().reset_index()\n",
    "            first = 0\n",
    "        else:\n",
    "            pixel_values = dd.merge(pixel_values,pixel_values_temp.copy().reset_index())\n",
    "\n",
    "    df_pixels = dd.merge(df_pixels,pixel_values)       \n",
    "    df_pixels = df_pixels.drop(['level_0','index'],axis = 1)    \n",
    "    df_pixels.compute()\n",
    "\n",
    "    # Now we add pop-weighted access times to columns in the dataframe\n",
    "    # Create a column per raster that we will populate with the corresponding raster's pop-weighted value\n",
    "    for rkey in rasters:\n",
    "        hrs_col = f\"{rkey}\"\n",
    "        avg_col_adm_2 = f\"{rkey}_avg_adm2\"\n",
    "        df_pixels[avg_col_adm_2] = df_pixels[hrs_col] * df_pixels['wt_adm_2']\n",
    "        if max_level == 'adm3':\n",
    "            avg_col_adm_3 = f\"{rkey}_avg_adm3\"\n",
    "            df_pixels[avg_col_adm_3] = df_pixels[hrs_col] * df_pixels['wt_adm_3']\n",
    "\n",
    "    float64_cols = df_pixels.select_dtypes(include='float64').columns\n",
    "    df_pixels = df_pixels.map_partitions(lambda df_pixels: df_pixels.astype({col: 'float32' for col in float64_cols}))\n",
    "\n",
    "    #clean some memory\n",
    "    del loaded_rasters ,pixel_values\n",
    "    del raster, rasters_ds\n",
    "\n",
    "    #prepare df for export\n",
    "    df_pixels = df_pixels.dropna()\n",
    "    df_pixels = df_pixels.repartition(partition_size=\"100MB\")\n",
    "    \n",
    "    #export dataframe to csv\n",
    "    df_pixels_out = access_dir + 'pixels' + '\\\\' + f\"{ssn_mode}_df_pixels_final-*.csv\"  # make sure you have a * or it will output parquet files       \n",
    "    df_pixels.to_csv(df_pixels_out, single_file=False)\n",
    "    \n",
    "    del df_pixels\n",
    "\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (git)",
   "language": "python",
   "name": "git"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
