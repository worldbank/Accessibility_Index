{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cddb5e8a-fae1-46fa-bd7e-0853dfb1b355",
   "metadata": {},
   "source": [
    "# Administrative Descriptive Stats - Merge results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f3f0c-603f-4f4c-85d7-88f5f4552cd9",
   "metadata": {},
   "source": [
    "This notebook simply merges all the separate tabular results determined in the previous notebook.  The outputs are the final tabular results with average service access times for different season-mode combinations, at specified adm levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92997b8-bc23-4481-9872-5ed6a68c8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import re\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95089688-653f-4ea5-b1b7-594121991556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_root = 'D:\\\\github_test\\\\'\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read project input parameters that will eventually be passed from the UI\n",
    "data_file = data_root + 'project_data.json'\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read project variables that will come from UI so that we have our parameters and file locations\n",
    "with open(data_file, 'rb') as f:\n",
    "    data_loaded = json.load(f)\n",
    "f.close()\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "#read information from the project setup file that's relevant to this section of code\n",
    "#imports\n",
    "local_population_folder = data_loaded['local_population_folder']\n",
    "local_lc_folder = data_loaded['local_lc_folder']\n",
    "access_dir = data_loaded['access_dir']\n",
    "dest_crs = data_loaded['dest_crs']\n",
    "dest_crs_id = data_loaded['dest_crs_id']\n",
    "\n",
    "local_boundaries_folder = data_loaded['local_boundaries_folder']\n",
    "level = data_loaded['level']\n",
    "max_level = data_loaded['max_level']\n",
    "\n",
    "if level != 'custom':\n",
    "    shapefile_adm_field = data_loaded['shapefile_adm_field']\n",
    "    adm_name = data_loaded['adm_name']\n",
    "\n",
    "seasons = sorted([os.path.join(local_lc_folder,file) \\\n",
    "            for file \\\n",
    "            in os.listdir(local_lc_folder) \\\n",
    "            if file.endswith(\".tif\")])\n",
    "\n",
    "for strnum in range(0, len(seasons)):\n",
    "    seasons[strnum] = str.replace(seasons[strnum], local_lc_folder,\"\")\n",
    "    seasons[strnum] = str.replace(seasons[strnum], \".tif\",\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b49e64-bb7e-43c7-82ee-a0ab15fc7918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mode_list =['walk','multi']\n",
    "ssn_mode_list = []\n",
    "for ssn in seasons:\n",
    "    for mode_num in range(0,len(mode_list)):\n",
    "        ssn_mode_list.append(ssn + \"_\" + mode_list[mode_num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e209eda-d579-437d-b14e-689d9d755f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read a csv file to get the 'base' adm columns\n",
    "folder_path = access_dir + 'tables' + '\\\\separate\\\\'\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is a CSV file\n",
    "    if filename.endswith('adm2_final.csv'):\n",
    "        # Construct the full path to the CSV file\n",
    "        file_path_adm2 = os.path.join(folder_path, filename)\n",
    "    if filename.endswith('adm3_final.csv'):\n",
    "        # Construct the full path to the CSV file\n",
    "        file_path_adm3 = os.path.join(folder_path, filename)\n",
    "\n",
    "dummy_URL = file_path_adm2\n",
    "Adm2_Code = pd.read_csv(os.path.join(dummy_URL),header=0,\n",
    "                                                usecols = [0,1])\\\n",
    "                                                .sort_values('Adm2_Code')\n",
    "adm2_base = Adm2_Code.copy()\n",
    "\n",
    "if max_level == 'adm3':\n",
    "    dummy_URL = file_path_adm3\n",
    "    Adm3_Code = pd.read_csv(os.path.join(dummy_URL),header=0,\n",
    "                                                    usecols = [0,1,2,3])\\\n",
    "                                                    .sort_values('Adm3_Code') \n",
    "    adm3_base = Adm3_Code.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e1467-26a6-4ffd-a268-6d9e5d88e1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adm2_final = adm2_base\n",
    "if max_level == 'adm3':\n",
    "    adm3_final = adm3_base\n",
    "\n",
    "adm2_start = 1\n",
    "adm3_start = 1\n",
    "\n",
    "for ssn_mode_index in range(0,len(ssn_mode_list)):\n",
    "# for ssn_mode_index in range(0,1):\n",
    "    ssn_mode = ssn_mode_list[ssn_mode_index]\n",
    "    print(ssn_mode)\n",
    "        \n",
    "    df_URL = access_dir + 'pixels' + '\\\\' + f\"{ssn_mode}_df_pixels_final-*.csv\"\n",
    "    df_pixels_source = dd.read_csv(os.path.join(df_URL),header=0,\n",
    "                                                na_values = ' ',\n",
    "                                                # usecols = col_range,\n",
    "                                                blocksize=100e6).head(n=1)\n",
    "\n",
    "    # Get the list of column names\n",
    "    column_names = df_pixels_source.columns\n",
    "\n",
    "    # List to store the column indices\n",
    "    column_indices = []\n",
    "\n",
    "    # Loop through column names to find the ones ending with \"_avg_adm2\" or \"_avg_adm3\"\n",
    "    for idx, col_name in enumerate(column_names):\n",
    "        if col_name.endswith('_avg_adm2') or col_name.endswith('_avg_adm3'):\n",
    "            column_indices.append(idx)\n",
    "                 \n",
    "    min_col_num = column_indices[0]\n",
    "    max_col_num = column_indices[len(column_indices)-1]+1  \n",
    "    \n",
    "    col_range = range(min_col_num,max_col_num)\n",
    "    service_index_range = range(0,max_col_num-min_col_num)\n",
    "\n",
    "    df_pixels = df_pixels_source.iloc[: ,col_range].copy()    \n",
    "    del df_pixels_source\n",
    "    col_list = df_pixels.columns\n",
    " \n",
    "    if adm2_start == 1:\n",
    "        adm2_first = 1\n",
    "        adm2_start = 0\n",
    "    else:\n",
    "        adm2_first = 0\n",
    "\n",
    "    if adm3_start == 1:\n",
    "        adm3_first = 1\n",
    "        adm3_start = 0\n",
    "    else:\n",
    "        adm3_first = 0\n",
    "    \n",
    "    for service_index in service_index_range:\n",
    "        read_service = col_list[service_index]\n",
    "        read_service_adm = read_service\n",
    "        read_service = read_service_adm[:-9]\n",
    "        adm_level = read_service_adm[-1]\n",
    "\n",
    "        # first we merge average access times\n",
    "        ##############\n",
    "        if adm_level == '2':            \n",
    "        \n",
    "            csv_URL = access_dir + 'tables' + '\\\\separate\\\\' + f\"{read_service_adm}_final.csv\"\n",
    "            current_data = pd.read_csv(os.path.join(csv_URL),header=0)\\\n",
    "                                                .sort_values('Adm2_Code')\n",
    "\n",
    "            column = current_data[[\"Adm2_Code\",read_service_adm,read_service_adm+'_idx']].copy()\n",
    "            adm2_final = pd.merge(adm2_final,column,on=[\"Adm2_Code\"])\n",
    "\n",
    "        else:\n",
    "\n",
    "            csv_URL = access_dir + 'tables' + '\\\\separate\\\\' + f\"{read_service_adm}_final.csv\"\n",
    "            current_data = pd.read_csv(os.path.join(csv_URL),header=0)\\\n",
    "                                                .sort_values('Adm3_Code')\n",
    "    \n",
    "            column = current_data[[\"Adm3_Code\",read_service_adm,read_service_adm+'_idx']].copy()\n",
    "            adm3_final = pd.merge(adm3_final,column,on=[\"Adm3_Code\"])\n",
    "\n",
    "        # Now we merge travel time bins\n",
    "        ############        \n",
    "        if adm_level == '2':\n",
    "            csv_URL = access_dir + 'tables' + '\\\\separate\\\\' + f\"{read_service_adm}_acc_indicators_long.csv\"\n",
    "            current_long_data_adm2 = pd.read_csv(os.path.join(csv_URL),header=0,\\\n",
    "                                                usecols = [0,1,2,3,4,5,6,7])\n",
    "\n",
    "            if adm2_first == 1:\n",
    "                adm2_long_final = current_long_data_adm2\n",
    "                adm2_first = 0\n",
    "            else:\n",
    "                adm2_long_final = pd.concat([adm2_long_final,current_long_data_adm2])\n",
    "\n",
    "        else:\n",
    "            csv_URL = access_dir + 'tables' + '\\\\separate\\\\' + f\"{read_service_adm}_acc_indicators_long.csv\"\n",
    "            current_long_data_adm3 = pd.read_csv(os.path.join(csv_URL),header=0,\\\n",
    "                                                usecols = [0,1,2,3,4,5,6,7,8,9])\n",
    "            if adm3_first == 1:\n",
    "                adm3_long_final = current_long_data_adm3\n",
    "                adm3_first = 0\n",
    "            else:\n",
    "                adm3_long_final = pd.concat([adm3_long_final,current_long_data_adm3])\n",
    "\n",
    "# Identify columns ending with '_idx'\n",
    "idx_columns = [col for col in adm2_final.columns if col.endswith('_idx')]\n",
    "other_columns = [col for col in adm2_final.columns if not col.endswith('_idx')]\n",
    "# Rearrange columns\n",
    "adm2_final = adm2_final[other_columns + idx_columns]\n",
    "\n",
    "# export final csv's!!!\n",
    "adm2_final.to_csv(access_dir + \"tables\\\\adm2_mean_final.csv\",index=False)\n",
    "if max_level == 'adm3':\n",
    "    # Identify columns ending with '_idx'\n",
    "    idx_columns = [col for col in adm3_final.columns if col.endswith('_idx')]\n",
    "    other_columns = [col for col in adm3_final.columns if not col.endswith('_idx')]\n",
    "    # Rearrange columns\n",
    "    adm3_final = adm3_final[other_columns + idx_columns]\n",
    "    adm3_final.to_csv(access_dir + \"tables\\\\adm3_mean_final.csv\",index=False)\n",
    "\n",
    "adm2_long_final.to_csv(access_dir + \"tables\\\\adm2_long_final.csv\",index=False)\n",
    "if max_level == 'adm3':\n",
    "    adm3_long_final.to_csv(access_dir + \"tables\\\\adm3_long_final.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
